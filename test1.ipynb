{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cac7447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# 1. 数据准备\n",
    "def load_poems(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        poems = [line.strip() for line in f.readlines() if len(line.strip()) > 0]\n",
    "    return poems\n",
    "\n",
    "# 2. 数据预处理\n",
    "def build_vocab(poems):\n",
    "    all_chars = [char for poem in poems for char in poem]\n",
    "    counter = Counter(all_chars)\n",
    "    char_freq = sorted(counter.items(), key=lambda x: -x[1])\n",
    "    chars = [char for char, freq in char_freq]\n",
    "    char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "    idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "    return char_to_idx, idx_to_char, len(chars)\n",
    "\n",
    "def poem_to_indices(poem, char_to_idx):\n",
    "    return [char_to_idx[char] for char in poem]\n",
    "\n",
    "def create_dataset(poems, char_to_idx, seq_length=50):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for poem in poems:\n",
    "        indices = poem_to_indices(poem, char_to_idx)\n",
    "        for i in range(0, len(indices) - seq_length):\n",
    "            inputs.append(indices[i:i+seq_length])\n",
    "            targets.append(indices[i+1:i+seq_length+1])\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "class PoemDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# 3. 模型构建\n",
    "class PoetryModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(PoetryModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.num_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden\n",
    "\n",
    "# 4. 训练函数\n",
    "def train_model(model, dataloader, epochs, learning_rate):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for batch, (inputs, targets) in enumerate(dataloader):\n",
    "            hidden = tuple([h.data for h in hidden])\n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Batch [{batch}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
    "            if batch % 10 == 0:\n",
    "                # 保存模型\n",
    "                torch.save(model.state_dict(), 'model/poetry_model_epoch_{}_batch_{}.pth'.format(epoch+1, batch))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# 5. 生成函数\n",
    "def generate_poem(model, idx_to_char, char_to_idx, start_string, \n",
    "                 poem_type='五言', temperature=0.8, max_lines=4):\n",
    "    \"\"\"\n",
    "    生成格式整齐的古诗\n",
    "    poem_type: 五言或七言\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 设置诗句长度\n",
    "    line_length = 5 if poem_type == '五言' else 7\n",
    "    separators = ['，', '。']\n",
    "    \n",
    "    # 初始化输入\n",
    "    input_seq = [char_to_idx[char] for char in start_string]\n",
    "    input_seq = torch.LongTensor(input_seq).unsqueeze(0)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    generated_poem = start_string\n",
    "    current_line_len = len(start_string)\n",
    "    lines = 1\n",
    "    expecting_separator = False\n",
    "    \n",
    "    while lines <= max_lines:\n",
    "        # 生成下一个字符\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        last_char_logits = output[:, -1, :] / temperature\n",
    "        probabilities = torch.softmax(last_char_logits, dim=-1)\n",
    "        predicted_idx = torch.multinomial(probabilities, 1).item()\n",
    "        predicted_char = idx_to_char[predicted_idx]\n",
    "        while not expecting_separator and predicted_char in separators:\n",
    "            probabilities[0][predicted_idx] = 0.0  # 避免重复\n",
    "            predicted_idx = torch.multinomial(probabilities, 1).item()\n",
    "            predicted_char = idx_to_char[predicted_idx]\n",
    "\n",
    "        \n",
    "        # 行长度控制\n",
    "        if not expecting_separator:\n",
    "            current_line_len += 1\n",
    "            # 达到指定长度时应该生成分隔符\n",
    "            if current_line_len == line_length:\n",
    "                expecting_separator = True\n",
    "        else:\n",
    "            # 检查是否是有效的分隔符\n",
    "            predicted_char='，' if lines%2==1 else '。'\n",
    "            predicted_idx = char_to_idx[predicted_char]\n",
    "            # if predicted_char not in separators:\n",
    "            #     predicted_char = random.choice(separators)\n",
    "            #     predicted_idx = char_to_idx[predicted_char]\n",
    "            lines += 1\n",
    "            current_line_len = 0\n",
    "            expecting_separator = False\n",
    "        generated_poem += predicted_char\n",
    "        input_seq = torch.LongTensor([predicted_idx]).unsqueeze(0)\n",
    "        if lines > max_lines:\n",
    "            break\n",
    "    \n",
    "    # # 后处理，确保最后以句号结束\n",
    "    # if not generated_poem.endswith('。'):\n",
    "    #     generated_poem += '。'\n",
    "    \n",
    "    # 格式化为每行一句\n",
    "    poem_lines = []\n",
    "    current_line = \"\"\n",
    "    for char in generated_poem:\n",
    "        current_line += char\n",
    "        if char in ['，', '。']:\n",
    "            poem_lines.append(current_line)\n",
    "            current_line = \"\"\n",
    "    \n",
    "    # # 确保偶数行（完整的对联）\n",
    "    # if len(poem_lines) % 2 != 0 and len(poem_lines) > 1:\n",
    "    #     poem_lines = poem_lines[:-1]\n",
    "    \n",
    "    return \"\\n\".join(poem_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef9ae17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "seq_length = 30\n",
    "batch_size = 781*2\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "# batch_size = 64\n",
    "# embedding_dim = 256\n",
    "# hidden_dim = 512\n",
    "num_layers = 2\n",
    "learning_rate = 0.1\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17a6ef0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 加载数据\n",
    "poems = load_poems('data/poems.txt')  # 替换为你的文件路径\n",
    "char_to_idx, idx_to_char, vocab_size = build_vocab(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8d136f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PoetryModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "model.load_state_dict(torch.load('model/poetry_model_epoch_200_batch_0.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0140dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "生成五言诗:\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春背乐岸轻，\n",
      "正情见说正。\n",
      "他年见去鸟，\n",
      "仙云高远当。\n",
      "\n",
      "以'夏'开头的五言诗:\n",
      "夏成水声涯，\n",
      "二十情用是。\n",
      "鹦鹉语中分，\n",
      "林泉从尘土。\n",
      "\n",
      "以'秋'开头的五言诗:\n",
      "秋水岸闲门，\n",
      "犀渠册经谢。\n",
      "频别我头钿，\n",
      "旧要秋渚花。\n",
      "\n",
      "以'冬'开头的五言诗:\n",
      "冬人花须乐，\n",
      "林云生陇首。\n",
      "任听吴书重，\n",
      "一风近头游。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春兴作地分琼琴，\n",
      "得青星夜舟横剑。\n",
      "锦书雁断应难寄，\n",
      "菱镜鸾孤貌可怜。\n",
      "\n",
      "以'夏'开头的七言诗:\n",
      "夏庭清耳路后和，\n",
      "虚殿云李犹闭寻。\n",
      "一琴笋屈盘穿大，\n",
      "旧制云中微云和。\n",
      "\n",
      "以'秋'开头的七言诗:\n",
      "秋水蛮立宿白画，\n",
      "夕阳啼高四义尽。\n",
      "千载路滑无羣素，\n",
      "山龙阙曙藏书洞。\n",
      "\n",
      "以'冬'开头的七言诗:\n",
      "冬稀竹开小分稍，\n",
      "疏木人展开鹦鹉。\n",
      "金印不到门北穷，\n",
      "朱颜何处掩别难。\n"
     ]
    }
   ],
   "source": [
    "start_chars = [\"春\",\"夏\",\"秋\",\"冬\"]\n",
    "\n",
    "print(\"\\n生成五言诗:\")\n",
    "\n",
    "for start in start_chars:\n",
    "    generated_poem = generate_poem(model, idx_to_char, char_to_idx, start, \n",
    "                                    poem_type='五言', temperature=1)\n",
    "    print(f\"\\n以'{start}'开头的五言诗:\")\n",
    "    print(generated_poem)\n",
    "\n",
    "print(\"\\n生成七言诗:\")\n",
    "for start in start_chars:\n",
    "    generated_poem = generate_poem(model, idx_to_char, char_to_idx, start, \n",
    "                                    poem_type='七言', temperature=1)\n",
    "    print(f\"\\n以'{start}'开头的七言诗:\")\n",
    "    print(generated_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4169d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
