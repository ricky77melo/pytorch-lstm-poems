{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cac7447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# 1. 数据准备\n",
    "def load_poems(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        poems = [line.strip() for line in f.readlines() if len(line.strip()) > 0]\n",
    "    return poems\n",
    "\n",
    "# 2. 数据预处理\n",
    "def build_vocab(poems):\n",
    "    all_chars = [char for poem in poems for char in poem]\n",
    "    counter = Counter(all_chars)\n",
    "    char_freq = sorted(counter.items(), key=lambda x: -x[1])\n",
    "    chars = [char for char, freq in char_freq]\n",
    "    char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "    idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "    return char_to_idx, idx_to_char, len(chars)\n",
    "\n",
    "def poem_to_indices(poem, char_to_idx):\n",
    "    return [char_to_idx[char] for char in poem]\n",
    "\n",
    "def create_dataset(poems, char_to_idx, seq_length=50):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for poem in poems:\n",
    "        indices = poem_to_indices(poem, char_to_idx)\n",
    "        for i in range(0, len(indices) - seq_length):\n",
    "            inputs.append(indices[i:i+seq_length])\n",
    "            targets.append(indices[i+1:i+seq_length+1])\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "class PoemDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# 3. 模型构建\n",
    "class PoetryModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(PoetryModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                  weight.new(self.num_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden\n",
    "\n",
    "# 4. 训练函数\n",
    "def train_model(model, dataloader, epochs, learning_rate):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        \n",
    "        for batch, (inputs, targets) in enumerate(dataloader):\n",
    "            hidden = tuple([h.data for h in hidden])\n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Batch [{batch}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
    "            if batch % 10 == 0:\n",
    "                # 保存模型\n",
    "                torch.save(model.state_dict(), 'model/poetry_model_epoch_{}_batch_{}.pth'.format(epoch+1, batch))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# 5. 生成函数\n",
    "def generate_poem(model, idx_to_char, char_to_idx, start_string, \n",
    "                 poem_type='五言', temperature=0.8, max_lines=4):\n",
    "    \"\"\"\n",
    "    生成格式整齐的古诗\n",
    "    poem_type: 五言或七言\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 设置诗句长度\n",
    "    line_length = 5 if poem_type == '五言' else 7\n",
    "    separators = ['，', '。']\n",
    "    \n",
    "    # 初始化输入\n",
    "    input_seq = [char_to_idx[char] for char in start_string]\n",
    "    input_seq = torch.LongTensor(input_seq).unsqueeze(0)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    generated_poem = start_string\n",
    "    current_line_len = len(start_string)\n",
    "    lines = 1\n",
    "    expecting_separator = False\n",
    "    \n",
    "    while lines <= max_lines:\n",
    "        # 生成下一个字符\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        last_char_logits = output[:, -1, :] / temperature\n",
    "        probabilities = torch.softmax(last_char_logits, dim=-1)\n",
    "        predicted_idx = torch.multinomial(probabilities, 1).item()\n",
    "        predicted_char = idx_to_char[predicted_idx]\n",
    "        while not expecting_separator and predicted_char in separators:\n",
    "            probabilities[0][predicted_idx] = 0.0  # 避免重复\n",
    "            predicted_idx = torch.multinomial(probabilities, 1).item()\n",
    "            predicted_char = idx_to_char[predicted_idx]\n",
    "\n",
    "        \n",
    "        # 行长度控制\n",
    "        if not expecting_separator:\n",
    "            current_line_len += 1\n",
    "            # 达到指定长度时应该生成分隔符\n",
    "            if current_line_len == line_length:\n",
    "                expecting_separator = True\n",
    "        else:\n",
    "            # 检查是否是有效的分隔符\n",
    "            predicted_char='，' if lines%2==1 else '。'\n",
    "            predicted_idx = char_to_idx[predicted_char]\n",
    "            # if predicted_char not in separators:\n",
    "            #     predicted_char = random.choice(separators)\n",
    "            #     predicted_idx = char_to_idx[predicted_char]\n",
    "            lines += 1\n",
    "            current_line_len = 0\n",
    "            expecting_separator = False\n",
    "        generated_poem += predicted_char\n",
    "        input_seq = torch.LongTensor([predicted_idx]).unsqueeze(0)\n",
    "        if lines > max_lines:\n",
    "            break\n",
    "    \n",
    "    # # 后处理，确保最后以句号结束\n",
    "    # if not generated_poem.endswith('。'):\n",
    "    #     generated_poem += '。'\n",
    "    \n",
    "    # 格式化为每行一句\n",
    "    poem_lines = []\n",
    "    current_line = \"\"\n",
    "    for char in generated_poem:\n",
    "        current_line += char\n",
    "        if char in ['，', '。']:\n",
    "            poem_lines.append(current_line)\n",
    "            current_line = \"\"\n",
    "    \n",
    "    # # 确保偶数行（完整的对联）\n",
    "    # if len(poem_lines) % 2 != 0 and len(poem_lines) > 1:\n",
    "    #     poem_lines = poem_lines[:-1]\n",
    "    \n",
    "    return \"\\n\".join(poem_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9ae17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "seq_length = 30\n",
    "batch_size = 781*2\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "# batch_size = 64\n",
    "# embedding_dim = 256\n",
    "# hidden_dim = 512\n",
    "num_layers = 2\n",
    "learning_rate = 0.1\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a6ef0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 加载数据\n",
    "poems = load_poems('data/poems.txt')  # 替换为你的文件路径\n",
    "char_to_idx, idx_to_char, vocab_size = build_vocab(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d21685f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23430, 30]), torch.Size([23430, 30]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建数据集\n",
    "X, y = create_dataset(poems, char_to_idx, seq_length)\n",
    "X = torch.from_numpy(X).long()\n",
    "y = torch.from_numpy(y).long()\n",
    "dataset = PoemDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3865e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PoetryModel(vocab_size, embedding_dim, hidden_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e21ff31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Batch [0/15], Loss: 8.0661\n",
      "Epoch [1/200], Batch [1/15], Loss: 7.9687\n",
      "Epoch [1/200], Batch [2/15], Loss: 7.2850\n",
      "Epoch [1/200], Batch [3/15], Loss: 6.8995\n",
      "Epoch [1/200], Batch [4/15], Loss: 6.7781\n",
      "Epoch [1/200], Batch [5/15], Loss: 6.6910\n",
      "Epoch [1/200], Batch [6/15], Loss: 6.6985\n",
      "Epoch [1/200], Batch [7/15], Loss: 6.7022\n",
      "Epoch [1/200], Batch [8/15], Loss: 6.6791\n",
      "Epoch [1/200], Batch [9/15], Loss: 6.6754\n",
      "Epoch [1/200], Batch [10/15], Loss: 6.6644\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46116\\717782788.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46116\\2967607076.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Wangruiqi\\anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46116\\2967607076.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Wangruiqi\\anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Wangruiqi\\anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d136f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PoetryModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "model.load_state_dict(torch.load('data2/test4model2/poetry_model_epoch_32_batch_0.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0140dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "生成五言诗:\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春虽故乡未，\n",
      "云霞五说与。\n",
      "云倚画树唱，\n",
      "离处隔鸡琴。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春分道只和惠志，\n",
      "聪间王州泪奔高。\n",
      "公朝手驿閒事已，\n",
      "华想家尘凤声来。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春卧稳自近，\n",
      "踟蹰路荣是。\n",
      "名成新词近，\n",
      "东篱影悬仙。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春过山卧兴衰旧，\n",
      "更阑分君臣可愁。\n",
      "离然散卧霜叶叶，\n",
      "青为断处我平归。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春驰栈知春，\n",
      "却在紫是含。\n",
      "祇遥雾势年，\n",
      "缓飘无辞穗。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春接修时遣扫望，\n",
      "枝堂梦得神居处。\n",
      "别后成旅路真踪，\n",
      "不得分分白醉故。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春鸿迎又棹，\n",
      "拾翠谁复响。\n",
      "远来浮世利，\n",
      "唤静为始堪。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春在食迳收前宝，\n",
      "抄得新书已在学。\n",
      "独听病依难照香，\n",
      "天惊后清飞时淅。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春赏古长终，\n",
      "有令自荒干。\n",
      "怡惊蝉展名，\n",
      "江淹散谩恋。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春分取欺炉香儒，\n",
      "清星对善友相未。\n",
      "便牵魂密犹吟影，\n",
      "公退斯得陇残红。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春虽自枯谙，\n",
      "直艇高斋轻。\n",
      "筹难名忽岭，\n",
      "兴后逢时绝。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春锁惊后岸垂钓，\n",
      "风卷喷云梦憾江。\n",
      "素道归路亦醉吟，\n",
      "暖歌尽鹭敲翠枝。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春讲似秋丝，\n",
      "留畔野去故。\n",
      "旌表宜颜古，\n",
      "心同入当欲。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春棹山圆非却屠，\n",
      "接印不独能肃物。\n",
      "竹逐春山尽石江，\n",
      "三泉石影轻曲印。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春虽了露中，\n",
      "红山只庭迟。\n",
      "幽窗前见问，\n",
      "春风春平鼻。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春棹笼霜起竹人，\n",
      "山光生寿老时髦。\n",
      "翅佩烟笼琴生冷，\n",
      "欲色芳受百笑知。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春卧九路赊，\n",
      "今松院恨长。\n",
      "警露吟出格，\n",
      "求化营年知。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春万事搜官事远，\n",
      "两礼岸烟霞高然。\n",
      "云霞曾时心惟来，\n",
      "自由俱汉绿微难。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春谩花光惆，\n",
      "无凭费叟烟。\n",
      "数家芦苇风，\n",
      "茱萸饮数春。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春莫在未为仙照，\n",
      "身无别随鬼流轻。\n",
      "意知更心常玉箸，\n",
      "故帆春幽景未迟。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春虽雁劳影，\n",
      "笛头前畴药。\n",
      "他年翻因佳，\n",
      "珠满明对密。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春鸿一筵金辂知，\n",
      "相喜紫照山上却。\n",
      "处世语锁迷陛戟，\n",
      "逸欢社心何上薄。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春辔长生紫，\n",
      "今日南屦恣。\n",
      "花我清自事，\n",
      "一时过巢无。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春穷隠上薄通理，\n",
      "青衫感台风掌筵。\n",
      "地来天白云迷枕，\n",
      "物气至未诗溪事。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春穷轩为等，\n",
      "夕阳须书人。\n",
      "征体是晨醒，\n",
      "自门前水组。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春未性庾兔憎嫌，\n",
      "乘轩水猿行竹不。\n",
      "窗前日暮花怨是，\n",
      "流才调巾箱学灵。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春卧床头欲，\n",
      "好看日为坐。\n",
      "若贪戏乱早，\n",
      "碧芙江年改。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春谩床戒覆门天，\n",
      "月有梁年红衣客。\n",
      "旧问行意无曾因，\n",
      "轻养通花崦应门。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春成惟贤书，\n",
      "渔浦经疏雨。\n",
      "林间竹有楚，\n",
      "朝浅三山碧。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春棹霁来长近来，\n",
      "日回红云草忆花。\n",
      "有越鸿相渐平十，\n",
      "衡杨柳只垂袂诸。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春分卧棘字，\n",
      "赞色直根琴。\n",
      "越国烟处跻，\n",
      "路上送人疏。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春鳞渥洼骢非载，\n",
      "丛边还闻籍地身。\n",
      "落清终不思知否，\n",
      "莲边春披琼蕴诵。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春驰栈深轮，\n",
      "舐犊自纷纷。\n",
      "花房犹神寻，\n",
      "四鬭棋身性。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春驰调事虽废侍，\n",
      "五有无门掩野何。\n",
      "香急梦寐一无篇，\n",
      "一酒有移泽一鹤。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春赏国息华，\n",
      "海离琴朱更。\n",
      "野色半映空，\n",
      "樵栏翻水乍。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春树蔽郊原上诏，\n",
      "松可涤昏垂赋诗。\n",
      "小离山岳栏隄镜，\n",
      "汎逐我自忻楼驰。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春人成须非，\n",
      "日对逍遥易。\n",
      "西游难池长，\n",
      "依心雁外明。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春驰栈独似千尺，\n",
      "银台上樵里为偶。\n",
      "溪景能是闭人来，\n",
      "莲袅红上重巅浮。\n",
      "\n",
      "以'春'开头的五言诗:\n",
      "春讲因礼映，\n",
      "花情冲湘筠。\n",
      "高节子陵静，\n",
      "疏味谿下荒。\n",
      "\n",
      "生成七言诗:\n",
      "\n",
      "以'春'开头的七言诗:\n",
      "春广怀籁炉烟微，\n",
      "依山掩然拂尘极。\n",
      "背想为别抛与此，\n",
      "迎香泉声酬日夜。\n"
     ]
    }
   ],
   "source": [
    "start_chars = [\"春\"]\n",
    "\n",
    "print(\"\\n生成五言诗:\")\n",
    "for i in range(20):\n",
    "    for start in start_chars:\n",
    "        generated_poem = generate_poem(model, idx_to_char, char_to_idx, start, \n",
    "                                        poem_type='五言', temperature=1)\n",
    "        print(f\"\\n以'{start}'开头的五言诗:\")\n",
    "        print(generated_poem)\n",
    "\n",
    "    print(\"\\n生成七言诗:\")\n",
    "    for start in start_chars:\n",
    "        generated_poem = generate_poem(model, idx_to_char, char_to_idx, start, \n",
    "                                        poem_type='七言', temperature=1)\n",
    "        print(f\"\\n以'{start}'开头的七言诗:\")\n",
    "        print(generated_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4169d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
